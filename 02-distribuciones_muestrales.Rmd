---
title: "Distribuciones muestrales asociadas con la Normal"
author: 
- Juan Sosa PhD
- Email   jcsosam@unal.edu.co
- GitHub  https://github.com/jstats1702 
date: ""
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Introducción

La distribución muestral de un estadístico depende de la distribución poblacional de la que se toma la muestra aleatoria. 

A continuación se estudian algunos estadísticos que se basan en una muestra aleatoria extraída de una distribución Normal.

**(Teorema.)** Si $X_1,\ldots,X_n$ es una colección de variables aleatorias independientes tales que $X_i\sim\textsf{Normal}(\mu_i,\sigma^2_i)$, para $i=1,\ldots,n$, y $a_1,\ldots, a_n$ es una colección de números reales, entones $\sum_{i=1}^n a_i X_i$ tiene distribución Normal con media $\sum_{i=1}^n a_i\mu_i$ y varianza $\sum_{i=1}^n a_i^2\sigma^2_i$.

*Demostración:*

La función generadora de momentos (fgm) de $Y = \sum_{i=1}^n a_i X_i$ es
$$
\begin{align*}
m_Y(t) &= \textsf{E}\left(\exp{\left[t\,Y\right]}\right) 
= \textsf{E}\left(\exp{\left[t\,\sum_{i=1}^n a_i X_i\right]}\right) 
= \textsf{E}\left(\prod_{i=1}^n\exp{\left[t\, (a_i X_i)\right]}\right) \\
&= \prod_{i=1}^n \textsf{E}\left(\exp{\left[t\, a_i X_i\right]}\right) \qquad\because\,\,\text{Independencia} \\ 
&= \prod_{i=1}^n m_{X_i}(t\,a_i) \qquad\because\,\,\text{Definición de fgm} \\
&= \prod_{i=1}^n \exp{\left[ \mu_i (t\,a_i) + \tfrac12\sigma^2_i(t\,a_i)^2 \right]} \qquad\because\,\,\text{fgm de la Normal} \\
&= \exp{\left[ t\,\left(\sum_{i=1}^n a_i \mu_i\right) + \tfrac12\left(\sum_{i=1}^n a_i^2\sigma^2_i\right)t^2 \right]}
\end{align*}
$$
lo que corresponde a la fgm de una variable aleatoria con distribución Normal con media $\mu_Y = \sum_{i=1}^n a_i \mu_i$ y varianza $\sigma_Y\sum_{i=1}^n a_i^2\sigma^2_i$. Por lo tanto, $Y\sim\textsf{Normal}(\mu_Y, \sigma^2_Y)$. 

**(Corolario.)** Si $X_1,\ldots,X_n$ es una muestra aleatoria de una población con distribución Normal con media $\mu$ y varianza $\sigma^2$, entonces $\bar{X}\sim\textsf{Normal}(\mu,\sigma^2/n)$, y por lo tanto, 
$$
\frac{\bar{X} - \mu}{\sigma/\sqrt{n}}\sim\textsf{Normal}(0,1)\,.
$$

*Demostración:* Ejercicio.


# Distribución Chi-cuadrado

La distribución **Chi-cuadrado** con $\nu$ grados de libertad es un caso particular de la **distribución Gamma** con parámetro de forma $\alpha = \nu/2$ y parámetro de razón $\beta = 1/2$, i.e., $\chi^2_n\equiv \text{Gamma}(n/2,1/2)$.

### Ejemplo {-}

Visualizar la función de densidad de probabilidad de una variable aleatoria con distribución $\chi^2_\nu$, para $\nu \in\{1,2,3,4,5\}$.

```{r, fig.align='center'}
# visualización
par(mar = c(3,3,1.5,1.5), mgp = c(1.75,0.75,0))
curve(expr = dchisq(x, df = 1), n = 1000, col = 1, from = 0, to = 15, ylim = c(0,0.5), xlab = "x", ylab = "f(x)", main = "Distribución Chi-cuadrado")
for (nu in 2:5)
  curve(expr = dchisq(x, df = nu), n = 1000, col = nu, add = T)
legend("topright", legend = paste0("v = ", 1:5), col = 1:5, lwd = 2, bty = "n")
```


**(Teorema.)** Si $X_1,\ldots,X_n$ es una colección de variables aleatorias independientes tales que $X_i\sim\chi^2_{\nu_i}$, para $i=1,\ldots,n$, entonces $\sum_{i=1}^n X_i$ tiene distribución Chi-cuadrado con $\sum_{i=1}^n \nu_i$ grados de libertad.

*Demostración:* Ejercicio. 

**(Teorema.)** Si $X\sim\textsf{Normal}(0,1)$, entonces $X^2\sim\chi^2_1$.

*Demostración:*

La fgm de $Y = X^2$ es
$$
\begin{align*}
m_Y(t) &= \textsf{E}\left(\exp{\left[t\,Y\right]}\right) = \textsf{E}\left(\exp{\left[t\,X^2\right]}\right) \\
&= \int_{-\infty}^\infty e^{t\,x^2}\,\frac{1}{\sqrt{2\pi}}\,e^{-x^2/2}\,\text{d}x = \int_{-\infty}^\infty \frac{1}{\sqrt{2\pi}}\,e^{-x^2(1-2t)/2}\,\text{d}x \\
&= \int_{-\infty}^\infty \frac{1}{\sqrt{1-2t}}\,\frac{1}{\sqrt{2\pi}}\,e^{-u^2/2}\,\text{d}u \qquad\because\,\,u = x\sqrt{1-2t}\,,\,\text{d}u = \sqrt{1-2t}\,\text{d}x\,,\,\text{para}\,\, t < 1/2  \\
&= (1-2t)^{-1/2}\qquad\because\,\, \int_{-\infty}^\infty e^{-u^2/2}\,\text{d}u = \sqrt{2\pi}
\end{align*}
$$
lo que corresponde a la fgm de una variable aleatoria con distribución Chi-cuadrado con 1 grado de libertad. Por lo tanto, $Y\sim\chi^2_1$.

**(Teorema.)** Si $X_1,\ldots,X_n$ es una muestra aleatoria de una población con distribución Normal con media $\mu$ y varianza $\sigma^2$, entonces
$$
\sum_{i=1}^n Z_i^2\sim\chi^2_n\,,
$$
donde $Z_i = (X_i-\mu)/\sigma$, para $i=1,\ldots,n$.

*Demostración:* Ejercicio. 

**(Teorema.)** Si $X_1,\ldots,X_n$ es una muestra aleatoria de una población con distribución Normal con media $\mu$ y varianza $\sigma^2$, entonces $\bar{X}$ y $S^2$ son independientes.

*Demostración:* Ver Mayorga (2004, pp. 32-33).

**(Teorema.)** Si $X_1,\ldots,X_n$ es una muestra aleatoria de una población con distribución Normal con media $\mu$ y varianza $\sigma^2$, entonces
$$
\frac{(n-1)S^2}{\sigma^2}\sim\chi^2_{n-1}\,.
$$

*Demostración:*

Primero, se observa que 
$$
\begin{align*}
\sum_{i=1}^n (X_i - \mu)^2 &= \sum_{i=1}^n ((X_i - \bar{X}) + (\bar{X} - \mu))^2 \\
&= \sum_{i=1}^n \left((X_i - \bar{X})^2 + 2(X_i - \bar{X})(\bar{X} - \mu) + (\bar{X} - \mu)^2\right) \\
&= (n-1)S^2 + n (\bar{X} - \mu)^2\qquad \because\,\,\sum_{i=1}^n(X_i - \bar{X}) = 0
\end{align*}
$$
y en consecuencia, $V = Y + W$, donde
$$
V = \sum_{i=1}^n \left(\frac{X_i - \mu}{\sigma}\right)^2\,,\qquad Y =\frac{(n-1)S^2}{\sigma^2}\,,\qquad  W = \left(\frac{\bar{X} - \mu}{\sigma/\sqrt{n}}\right)^2\,.
$$

Así, la fgm de $V$ es 
$$
\begin{align*}
m_V(t) &= \textsf{E}\left(\exp{\left[t\,V\right]}\right) \\
&= \textsf{E}\left(\exp{\left[t\,Y\right]}\,\exp{\left[t\,W\right]}\right) \\
&= \textsf{E}\left(\exp{\left[t\,Y\right]}\right)\,\textsf{E}\left(\exp{\left[t\,W\right]}\right)\qquad\because\,\,\bar{X}\,\,\text{y}\,\,S^2\,\,\text{son independientes} \\
&= m_Y(t)\,m_W(t)\,.
\end{align*}
$$

Como $V\sim\chi^2_n$ y $W\sim\chi^2_1$, entonces se tiene que
$(1-2t)^{-n/2} = m_Y(t)\,(1-2t)^{-1/2}$, para $t < 1/2$, de donde
$$
m_Y(t) = (1-2t)^{-(n-1)/2}\,,
$$
lo que corresponde a la fgm de una variable aleatoria con distribución Chi-cuadrado con $n-1$ grado de libertad, ,i.e., $T\sim\textsf{t}_n$ . Por lo tanto, $Y\sim\chi^2_{n-1}$.


# Distribución $\textsf{t}$

**(Definición.)** Si $Z$ y $Y$ son variables aleatorias independientes tales que $Z\sim\textsf{Normal}(0,1)$ y $V\sim\chi^2_n$, entonces se dice que la variable aleatoria
$$
T = \frac{Z}{\sqrt{V/n}}
$$
tiene distribución $\textsf{t}$ Student con $n$ grados de libertad. En este caso, se tiene que
$$
f_T(x) = \frac{1}{\sqrt{\pi\,n}}\,\frac{\Gamma\left( \frac{n+1}{2} \right)}{\Gamma\left( \frac{n}{2} \right)}\,\left( 1 + \frac{x^2}{n} \right)^{-(n+1)/2}\,,\qquad -\infty < x < \infty\,.
$$

Dos definiciones populares para $e^x$ son
$$
e^x= \lim_{n\to\infty} \left(1 + \frac{x}{n}\right)^{n}
\qquad\text{y}\qquad
e^x = \sum_{n=0}^\infty \frac{x^n}{n!}\,.
$$


### Ejemplo {-}

Visualizar la función de densidad de probabilidad de una variable aleatoria con distribución $\textsf{t}_\nu$, para $\nu\in\{1,2,3,4,5\}$.

```{r, fig.align='center'}
# visualización
par(mar = c(3,3,1.5,1.5), mgp = c(1.75,0.75,0))
curve(expr = dt(x, df = 1), n = 1000, col = 1, from = -5, to = 5, ylim = c(0,0.4), xlab = "x", ylab = "f(x)", main = "Distribución t Student")
for (nu in 2:5)
  curve(expr = dt(x, df = nu), n = 1000, col = nu, add = T)
curve(expr = dnorm(x), n = 1000, col = "gray", lwd = 3, add = T)
legend("topright", legend = c(paste0("v = ", 1:5), "Z"), col = c(1:5,"gray"), lwd = 2, bty = "n")
```

La distribución Normal estándar proporciona una **"buena aproximación"** (convergencia en distribución) a la distribución $\textsf{t}$ para tamaños de muestra de mayores o iguales a 30. La demostración se puede consultar en Hogg, McKean \& Craig (2018, p. 330).

*(Teorema.)* Si $X_1,\ldots,X_n$ es una muestra aleatoria de una población con distribución Normal con media $\mu$ y varianza $\sigma^2$, entonces
$$
\frac{\bar{X} - \mu}{S/\sqrt{n}}\sim\textsf{t}_{n-1}\,.
$$

*Demostración:*

Como $\bar{X}$ y $S^2$ son independientes, y además,
$$
\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}\sim\textsf{Normal}(0,1)
\qquad\text{y}\qquad
\frac{(n-1)S^2}{\sigma^2}\sim\chi^2_{n-1}\,,
$$
entonces
$$
\begin{align*}
\frac{\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}}{\sqrt{\frac{\frac{(n-1)S^2}{\sigma^2}}{n-1}}}
&= \frac{\bar{X}-\mu}{S/\sqrt{n}}\sim\textsf{t}_{n-1}\,.
\end{align*}
$$


# Distribución $\textsf{F}$

**(Definición.)** Si $V$ y $W$ son variables aleatorias independientes tales que $V\sim\chi^2_n$ y $W\sim\chi^2_m$, entonces se dice que la variable aleatoria
$$
F = \frac{V/n}{W/m}
$$
tiene distribución $\textsf{F}$ $n$ grados de libertad en numerador y $m$ grados de libertad en el denominador, i.e., $F\sim\textsf{F}_{n,m}$. En este caso, se tiene que
$$
f_F(x) = \frac{\Gamma\left(\frac{n+m}{2}\right)}{\Gamma\left(\frac{n}{2}\right)\,\Gamma\left(\frac{m}{2}\right)}\,\left(\frac{n}{m}\right)^{n/2}\,x^{n/2 - 1}\,\left(1 + \frac{n}{m}\,x\right)^{-(n+m)/2} \,,\qquad x > 0\,.
$$

### Ejemplo {-}

Visualizar la función de densidad de probabilidad de una variable aleatoria con distribución $\textsf{F}_{5,5}$, $\textsf{F}_{5,10}$, $\textsf{F}_{10,5}$ y $\textsf{F}_{10,10}$.

```{r, fig.align='center'}
# visualización
par(mar = c(3,3,1.5,1.5), mgp = c(1.75,0.75,0))
curve(expr = df(x, df1 = 5,  df2 = 5 ), n = 1000, col = 1, from = 0, to = 6, ylim = c(0,0.8), xlab = "x", ylab = "f(x)", main = "Distribución F")
curve(expr = df(x, df1 = 5,  df2 = 10), n = 1000, col = 2, add = T)
curve(expr = df(x, df1 = 10, df2 = 5 ), n = 1000, col = 3, add = T)
curve(expr = df(x, df1 = 10, df2 = 10), n = 1000, col = 4, add = T)
legend("topright", legend = c("n = 5, m = 5", "n = 5, m = 10", "n = 10, m = 5", "n = 10, m = 10"), col = 1:4, lwd = 2, bty = "n")
```

**(Teorema.)** Si $X_1,\ldots,X_n$ y $Y_1,\ldots,Y_m$ son dos muestras aleatorias independientes de poblaciones Normales con medias $\mu_X$ y $\mu_Y$ y varianzas $\sigma^2_X$ y $\sigma^2_Y$, respectivamente, entonces  
$$
\frac{S^2_X/\sigma^2_X}{S^2_Y/\sigma^2_Y}\sim\textsf{F}_{n-1.m-1}
$$
donde $S_X$ y $S^2_Y$ son las medias muestrales de  $X_1,\ldots,X_n$ y $Y_1,\ldots,Y_m$, respectivamente.

*Demostración:* Ejercicio.


# Referencias {-}

```{r, eval = TRUE, echo=FALSE, out.width="25%", fig.pos = 'H', fig.align = 'center'}
knitr::include_graphics("mayorga.jpg")
```

```{r, eval = TRUE, echo=FALSE, out.width="25%", fig.pos = 'H', fig.align = 'center'}
knitr::include_graphics("ramachandran_tsokos.png")
```

```{r, eval = TRUE, echo=FALSE, out.width="25%", fig.pos = 'H', fig.align = 'center'}
knitr::include_graphics("casella_berger.jpg")
```
